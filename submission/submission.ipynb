{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter, attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fcs = nn.Sequential(\n",
    "                    nn.Linear(228942, 512),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(256, 128),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Linear(128, 23418),\n",
    "                )\n",
    "    def forward(self, input_data):\n",
    "        feature = self.fcs(input_data)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strangely, current torch implementation of csr tensor do not accept to be moved to the gpu. \n",
    "# So we make our own equivalent class\n",
    "TorchCSR = collections.namedtuple(\"TrochCSR\", \"data indices indptr shape\")\n",
    "\n",
    "def load_csr_data_to_gpu(train_inputs):\n",
    "    \"\"\"Move a scipy csr sparse matrix to the gpu as a TorchCSR object\n",
    "    This try to manage memory efficiently by creating the tensors and moving them to the gpu one by one\n",
    "    \"\"\"\n",
    "    th_data = torch.from_numpy(train_inputs.data).to(device)\n",
    "    th_indices = torch.from_numpy(train_inputs.indices).to(device)\n",
    "    th_indptr = torch.from_numpy(train_inputs.indptr).to(device)\n",
    "    th_shape = train_inputs.shape\n",
    "    return TorchCSR(th_data, th_indices, th_indptr, th_shape)\n",
    "\n",
    "def make_coo_batch(torch_csr, indx):\n",
    "    \"\"\"Make a coo torch tensor from a TorchCSR object by taking the rows indicated by the indx tensor\n",
    "    \"\"\"\n",
    "    th_data, th_indices, th_indptr, th_shape = torch_csr\n",
    "    start_pts = th_indptr[indx]\n",
    "    end_pts = th_indptr[indx+1]\n",
    "    coo_data = torch.cat([th_data[start_pts[i]: end_pts[i]] for i in range(len(start_pts))], dim=0)\n",
    "    coo_col = torch.cat([th_indices[start_pts[i]: end_pts[i]] for i in range(len(start_pts))], dim=0)\n",
    "    coo_row = torch.repeat_interleave(torch.arange(indx.shape[0], device=device), th_indptr[indx+1] - th_indptr[indx])\n",
    "    coo_batch = torch.sparse_coo_tensor(torch.vstack([coo_row, coo_col]), coo_data, [indx.shape[0], th_shape[1]])\n",
    "    return coo_batch\n",
    "\n",
    "\n",
    "def make_coo_batch_slice(torch_csr, start, end):\n",
    "    \"\"\"Make a coo torch tensor from a TorchCSR object by taking the rows within the (start, end) slice\n",
    "    \"\"\"\n",
    "    th_data, th_indices, th_indptr, th_shape = torch_csr\n",
    "    if end > th_shape[0]:\n",
    "        end = th_shape[0]\n",
    "    start_pts = th_indptr[start]\n",
    "    end_pts = th_indptr[end]\n",
    "    coo_data = th_data[start_pts: end_pts]\n",
    "    coo_col = th_indices[start_pts: end_pts]\n",
    "    coo_row = torch.repeat_interleave(torch.arange(end-start, device=device), th_indptr[start+1:end+1] - th_indptr[start:end])\n",
    "    coo_batch = torch.sparse_coo_tensor(torch.vstack([coo_row, coo_col]), coo_data, [end-start, th_shape[1]])\n",
    "    return coo_batch\n",
    "\n",
    "class DataLoaderCOO:\n",
    "    \"\"\"Torch compatible DataLoader. Works with in-device TorchCSR tensors.\n",
    "    Args:\n",
    "         - train_inputs, train_targets: TorchCSR tensors\n",
    "         - train_idx: tensor containing the indices of the rows of train_inputs and train_targets that should be used\n",
    "         - batch_size, shuffle, drop_last: as in torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "    def __init__(self, train_inputs, train_targets, train_idx=None, \n",
    "                 *,\n",
    "                batch_size=512, shuffle=False, drop_last=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "        \n",
    "        self.train_inputs = train_inputs\n",
    "        self.train_targets = train_targets\n",
    "        \n",
    "        self.train_idx = train_idx\n",
    "        \n",
    "        self.nb_examples = len(self.train_idx) if self.train_idx is not None else train_inputs.shape[0]\n",
    "        \n",
    "        self.nb_batches = self.nb_examples//batch_size\n",
    "        if not drop_last and not self.nb_examples%batch_size==0:\n",
    "            self.nb_batches +=1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            shuffled_idx = torch.randperm(self.nb_examples, device=device)\n",
    "            if self.train_idx is not None:\n",
    "                idx_array = self.train_idx[shuffled_idx]\n",
    "            else:\n",
    "                idx_array = shuffled_idx\n",
    "        else:\n",
    "            if self.train_idx is not None:\n",
    "                idx_array = self.train_idx\n",
    "            else:\n",
    "                idx_array = None\n",
    "            \n",
    "        for i in range(self.nb_batches):\n",
    "            slc = slice(i*self.batch_size, (i+1)*self.batch_size)\n",
    "            if idx_array is None:\n",
    "                inp_batch = make_coo_batch_slice(self.train_inputs, i*self.batch_size, (i+1)*self.batch_size)\n",
    "                if self.train_targets is None:\n",
    "                    tgt_batch = None\n",
    "                else:\n",
    "                    tgt_batch = make_coo_batch_slice(self.train_targets, i*self.batch_size, (i+1)*self.batch_size)\n",
    "            else:\n",
    "                idx_batch = idx_array[slc]\n",
    "                inp_batch = make_coo_batch(self.train_inputs, idx_batch)\n",
    "                if self.train_targets is None:\n",
    "                    tgt_batch = None\n",
    "                else:\n",
    "                    tgt_batch = make_coo_batch(self.train_targets, idx_batch)\n",
    "            yield inp_batch, tgt_batch\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.nb_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pred Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"../multi/multi_MSE.pt\"))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = sp.load_npz(\"../transfered_file/test_multi_inputs_values.sparse.npz\")\n",
    "test_inputs = load_csr_data_to_gpu(test_inputs)\n",
    "\n",
    "dl_test = DataLoaderCOO(test_inputs, None, train_idx=None,\n",
    "                batch_size=512, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = torch.empty(\n",
    "        (dl_test.nb_examples, 23418), \n",
    "        device='cpu', dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = 0\n",
    "for i, inpt in enumerate(dl_test):\n",
    "    pred = model(inpt[0]).detach().cpu()\n",
    "    test_pred[cur:cur+pred.shape[0]] = pred\n",
    "    cur += pred.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55935, 23418])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ids = pd.read_parquet(\"../transfered_file/evaluation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ids.cell_id = eval_ids.cell_id.astype(pd.CategoricalDtype())\n",
    "eval_ids.gene_id = eval_ids.gene_id.astype(pd.CategoricalDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series(name='target',\n",
    "                       index=pd.MultiIndex.from_frame(eval_ids), \n",
    "                       dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 230 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_columns = np.load(\"../transfered_file/train_multi_targets_idxcol.npz\",\n",
    "                   allow_pickle=True)[\"columns\"]\n",
    "\n",
    "test_index = np.load(\"../transfered_file/test_multi_inputs_idxcol.npz\",\n",
    "                    allow_pickle=True)[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dict = dict((k,v) for v,k in enumerate(test_index)) \n",
    "assert len(cell_dict)  == len(test_index)\n",
    "\n",
    "gene_dict = dict((k,v) for v,k in enumerate(y_columns))\n",
    "assert len(gene_dict) == len(y_columns)\n",
    "\n",
    "eval_ids_cell_num = eval_ids.cell_id.apply(lambda x:cell_dict.get(x, -1))\n",
    "eval_ids_gene_num = eval_ids.gene_id.apply(lambda x:gene_dict.get(x, -1))\n",
    "\n",
    "valid_multi_rows = (eval_ids_gene_num !=-1) & (eval_ids_cell_num!=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20687, 15183, 17190, ...,  9200,  9012, 20487], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_multi_rows = valid_multi_rows.to_numpy()\n",
    "eval_ids_gene_num[valid_multi_rows].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[valid_multi_rows] = test_pred[eval_ids_cell_num[valid_multi_rows].to_numpy(),\n",
    "eval_ids_gene_num[valid_multi_rows].to_numpy()].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id    cell_id       gene_id        \n",
       "0         c2150f55becb  CD86                    NaN\n",
       "1         c2150f55becb  CD274                   NaN\n",
       "2         c2150f55becb  CD270                   NaN\n",
       "3         c2150f55becb  CD155                   NaN\n",
       "4         c2150f55becb  CD112                   NaN\n",
       "                                             ...   \n",
       "65744175  2c53aa67933d  ENSG00000134419    6.419917\n",
       "65744176  2c53aa67933d  ENSG00000186862    0.031934\n",
       "65744177  2c53aa67933d  ENSG00000170959    0.031995\n",
       "65744178  2c53aa67933d  ENSG00000107874    1.464669\n",
       "65744179  2c53aa67933d  ENSG00000166012    4.627115\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.reset_index(drop=True, inplace=True)\n",
    "submission.index.name = 'row_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_submission = pd.read_csv(\"./citeseq_submission.csv\")\n",
    "cite_submission = cite_submission.set_index(\"row_id\")\n",
    "cite_submission = cite_submission[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[submission.isnull()] = cite_submission[submission.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id\n",
       "0           0.094605\n",
       "1          -0.162362\n",
       "2          -0.405332\n",
       "3          -0.302582\n",
       "4           1.114355\n",
       "              ...   \n",
       "65744175    6.419917\n",
       "65744176    0.031934\n",
       "65744177    0.031995\n",
       "65744178    1.464669\n",
       "65744179    4.627115\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0abf52f7dff1bbf2191b90c10bb43e97e891f8d70dafe2d0c71717742c591866"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
